\documentclass[UTF8]{article}
\usepackage{ctex}
\usepackage{amsmath}
\usepackage{amssymb}
\begin{document}
\section{系统结构}
\subsection{输入输出}
采用端到端训练方案，神经网络的输入为接受信号$Y$，输出为解调后的估计信号$\widehat{X}$，其中对于输入的导频部分我们做了一些处理，只保留了插入导频子载波位置的接收信号，对于32导频的就是每8个子载波插入一个导频，由于错开半个导频间隔的位置，因此在接收端每隔4个子载波提取一个导频，其他位置视作噪声丢弃可以减少无用噪声的影响。
\subsection{预分类网络}
首先生成大量mode 0，1，2均匀分布的样本信道，以mode作为标签，以接收导频为输入进行分类预测，采用DNN训练，准确率对于32导频本地验证集可达0.98，而8导频可达0.9。网络结构采用普通DNN。随后对给定的测试测试集数据中的导频进行分类预测，可以观察到绝大多数样本mode都为0，因此我们在下一步对信号解调网络进行训练时训练集全部采用mode0。
\subsection{网络结构}
将输入的接收信号$Y$拆分成两部分，第一部分为导频信号$Y_p \in \mathbb{R}^{1\times 2P\times 4}$,第二个为数据信号$Y_d \in \mathbb{R}^{1\times N_c\times 4}$,导频信号$Y_p$首先展开经过一次dense层维度增大一倍并重构成维度为$1\times N_c \times 16$的数据流，可以将其看作是初步隐形的信道估计，随后采用补零的维度不变的卷积残差网络进一步细化我们的隐式估计信道，为了之后的神经网络模拟信道均衡与解调的过程因此将这个数据流看作是非显示的估计信道并且为了能提供更多信息比真实频域信道扩大一倍。然后将此数据流与数据信号在第三个维度拼接并经过一次卷积将通道数扩大以获取更多的特征。随后并经过第二个卷积残差网络，最后再经过一次卷积层输出通道数为4将输出数据维度变换为$1\times N_c\times 4$最后经过sigmoid激活函数并判决即为输出的预测比特流，将其按照天线与子载波与调制顺序的关系重新排列成长度为1024的比特流，网络中总共有两大块卷积残差网络，第一块是为了隐式估计信道，第二块是为了解调数据考虑子载波间的相关性，其中第二块对于通道采用attention机制。
\section{训练过程}
直接用生成器，并用H.bin文件的320000个信道不断生成训练数据进行训练。并用H$\_$val.bin的信道作为生成验证集的信道进行验证不断保存验证集精度最高的模型。
\section{参数设置}
第一个残差块维度较小，分别为16，32，64层以精细化因隐式估计信道。第二个残差块为了解调数据维度较大，每个残差块内有3个卷积层，输出通道数分别为512，1024，256。两组残差块卷积核大小都为$1\times 7$,相当于一维卷积，padding采用`same'。采用Adam优化器进行优化。每100个epoches学习率$\times$0.5,$batch\_ size$=128。
\section{分集与最大似然合并}
我们采用相似的网络参数进行多次训练，训练出多个性能与结构相似但是独立的网络，采用多个网络对接收信号进行解调，得到多个数据流。这些独立的数据流承载着相同的信息，可以看成是一种信号的分集，我们可以利用分集增益提升我们的性能。这里我们采用最大似然合并来处理这些数据流，即对于每个比特的判决根据该位置上0和1出现在各个数据流的次数的多少来判决为1或者为0.
\end{document}